{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "#selected_features_1 = df[[\"koi_period\",\"koi_time0bk\",\"koi_impact\",\"koi_duration\",\"koi_depth\",\"koi_prad\",\n",
    "#                        \"koi_teq\",\"koi_insol\",\"koi_model_snr\",\"koi_tce_plnt_num\",\"koi_steff\",\"koi_slogg\",\n",
    "#                        \"koi_srad\",\"ra\",\"dec\",\"koi_kepmag\"]]\n",
    "selected_features_1 = df.loc[:, df.columns != 'koi_disposition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features_2 = df[[\"koi_impact\",\"koi_duration\",\"koi_depth\",\"ra\",\"koi_kepmag\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = selected_features_1\n",
    "X2 = selected_features_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SWITCH STRING TO NUMBER FOR Y\n",
    "df.loc[df[\"koi_disposition\"]==\"CONFIRMED\"]=0\n",
    "df.loc[df[\"koi_disposition\"]==\"FALSE POSITIVE\"]=1\n",
    "df.loc[df[\"koi_disposition\"]==\"CANDIDATE\"]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"koi_disposition\"].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6991, 40) (6991, 1)\n",
      "(6991, 5) (6991, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X1.shape, y.shape)\n",
    "print(X2.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X1 = pd.get_dummies(X1)\n",
    "#X2 = pd.get_dummies(X2)\n",
    "#y = pd.get_dummies(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5243, 40) (5243, 1)\n",
      "(1748, 40) (1748, 1)\n"
     ]
    }
   ],
   "source": [
    "#Feature 1\n",
    "\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1, y, random_state=42)\n",
    "\n",
    "print(X1_train.shape, y_train.shape)\n",
    "print(X1_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>ra</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6122</td>\n",
       "      <td>0.150</td>\n",
       "      <td>3.61600</td>\n",
       "      <td>123.1</td>\n",
       "      <td>294.40472</td>\n",
       "      <td>14.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6370</td>\n",
       "      <td>0.291</td>\n",
       "      <td>2.30900</td>\n",
       "      <td>114.6</td>\n",
       "      <td>284.50391</td>\n",
       "      <td>15.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2879</td>\n",
       "      <td>0.970</td>\n",
       "      <td>79.89690</td>\n",
       "      <td>641.1</td>\n",
       "      <td>295.50211</td>\n",
       "      <td>13.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.300</td>\n",
       "      <td>2.63120</td>\n",
       "      <td>875.4</td>\n",
       "      <td>291.15878</td>\n",
       "      <td>15.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.831</td>\n",
       "      <td>2.22739</td>\n",
       "      <td>9802.0</td>\n",
       "      <td>292.16705</td>\n",
       "      <td>15.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_impact  koi_duration  koi_depth         ra  koi_kepmag\n",
       "6122       0.150       3.61600      123.1  294.40472      14.725\n",
       "6370       0.291       2.30900      114.6  284.50391      15.770\n",
       "2879       0.970      79.89690      641.1  295.50211      13.099\n",
       "107        0.300       2.63120      875.4  291.15878      15.660\n",
       "29         0.831       2.22739     9802.0  292.16705      15.263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature 2\n",
    "\n",
    "X2_train, X2_test, y_train, y_test = train_test_split(X2, y, random_state=42)\n",
    "\n",
    "X2_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMaxScaler- Feature 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X1_minmax = MinMaxScaler().fit(X1)\n",
    "y_minmax = MinMaxScaler().fit(y)\n",
    "\n",
    "X1_train_minmax = X1_minmax.transform(X1_train)\n",
    "X1_test_minmax = X1_minmax.transform(X1_test)\n",
    "y_train_minmax = y_minmax.transform(y_train)\n",
    "y_test_minmax = y_minmax.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMaxScaler- Feature 2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X2_minmax = MinMaxScaler().fit(X2_train)\n",
    "y_minmax = MinMaxScaler().fit(y_train)\n",
    "\n",
    "X2_train_minmax = X2_minmax.transform(X2_train)\n",
    "X2_test_minmax = X2_minmax.transform(X2_test)\n",
    "y_train_minmax = y_minmax.transform(y_train)\n",
    "y_test_minmax = y_minmax.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION- Feature 1\n",
    "model.fit(X1_train_minmax, y_train_minmax)\n",
    "training_score_1 = model.score(X1_train_minmax, y_train_minmax)\n",
    "testing_score_1 = model.score(X1_test_minmax, y_test_minmax)\n",
    "### END SOLUTION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.10138681286706097\n",
      "Testing Score: 0.08165028294908339\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Score: {training_score_1}\")\n",
    "print(f\"Testing Score: {testing_score_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION- Feature 2\n",
    "model.fit(X2_train_minmax, y_train_minmax)\n",
    "training_score_2 = model.score(X2_train_minmax, y_train_minmax)\n",
    "testing_score_2 = model.score(X2_test_minmax, y_test_minmax)\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.0035717383547523296\n",
      "Testing Score: 0.005986191897429438\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Score: {training_score_2}\")\n",
    "print(f\"Testing Score: {testing_score_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), make_column_selector(dtype_include=np.number)),\n",
    "    (OneHotEncoder(), make_column_selector(dtype_include=object))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing\n",
    "\n",
    "# Data Feature one with Feature 1\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1, y, random_state=42)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elasticnet__alpha': 0.01} 0.09121280475209761\n",
      "{'ridge__alpha': 10.0} 0.0462417767937777\n",
      "{'lasso__alpha': 0.01} 0.08957093186817253\n"
     ]
    }
   ],
   "source": [
    "# Train the model with GridSearch for Feature 1\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def run_grid_search(name, model, alpha_params=[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0], verbose=3):\n",
    "    param_grid = {f\"{name.lower()}__alpha\": alpha_params}\n",
    "    grid = GridSearchCV(model, param_grid, verbose=verbose)\n",
    "    grid.fit(X1_train, y_train)\n",
    "    return grid\n",
    "\n",
    "models_1 = [LinearRegression(), ElasticNet(alpha=.01), Ridge(alpha=.01), Lasso(alpha=.01)]\n",
    "for model in models_1:\n",
    "    name = type(model).__name__\n",
    "    if name.lower() == \"linearregression\":\n",
    "        continue\n",
    "    model = make_pipeline(ct, model).fit(X1_train, y_train)\n",
    "    grid_1 = run_grid_search(name, model, verbose=0) # 0- quit, 3 - verbose\n",
    "    print(grid_1.best_params_, grid_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Feature one with Feature 2\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X2_train, X2_test, y_train, y_test = train_test_split(X2, y, random_state=42)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elasticnet__alpha': 0.01} 0.0017687182021199678\n",
      "{'ridge__alpha': 10.0} 0.001732727107303611\n",
      "{'lasso__alpha': 0.001} 0.00173354136581505\n"
     ]
    }
   ],
   "source": [
    "# Train the model with GridSearch for Feature 2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def run_grid_search(name, model, alpha_params=[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0], verbose=3):\n",
    "    param_grid = {f\"{name.lower()}__alpha\": alpha_params}\n",
    "    grid = GridSearchCV(model, param_grid, verbose=verbose)\n",
    "    grid.fit(X2_train, y_train)\n",
    "    return grid\n",
    "\n",
    "models = [LinearRegression(), ElasticNet(alpha=.01), Ridge(alpha=.01), Lasso(alpha=.01)]\n",
    "for model in models:\n",
    "    name = type(model).__name__\n",
    "    if name.lower() == \"linearregression\":\n",
    "        continue\n",
    "    model = make_pipeline(ct, model).fit(X2_train, y_train)\n",
    "    grid_2 = run_grid_search(name, model, verbose=0) # 0- quit, 3 - verbose\n",
    "    print(grid_2.best_params_,grid_2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yin_cai.sav']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename_1 =\"yin_cai_1.sav\"\n",
    "filename = 'yin_cai.sav'\n",
    "joblib.dump(models_1, filename_1)\n",
    "joblib.dump(models, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
